{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_torch.torch_original import DeepConvNetTorch\n",
    "from models.torch_original import DeepConvNetTorch as DeepConvNetNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/dummy_data.pkl\", 'rb') as f:\n",
    "    dummy_data = pickle.load(f)\n",
    "\n",
    "dummy_data = iter(dummy_data)\n",
    "\n",
    "im_data, gt_boxes, gt_classes, num_obj = next(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data, gt_boxes, gt_classes, num_obj = im_data.cuda(), gt_boxes.cuda(), gt_classes.cuda(), num_obj.cuda()\n",
    "im_data2, gt_boxes2, gt_classes2, num_obj2 = im_data.clone(), gt_boxes.clone(), gt_classes.clone(), num_obj.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing outputs for Forward:\n",
      "  Forward[0]:\n",
      "    Shape: (8, 125, 13, 13)\n",
      "    Max absolute difference: 0.0\n",
      "    Mean absolute difference: 0.0\n",
      "    PASS: All differences within tolerance of 1e-05\n",
      "  Forward[1]: Cannot compare. Torch type: <class 'dict'>, Numpy type: <class 'dict'>\n",
      "\n",
      "\n",
      "torch.Size([15, 20]) torch.Size([15])\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.1954, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Tensor(0.23352785) Tensor(2.19544194) Tensor(0.13472709)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compare_outputs(torch_output, numpy_output, function_name, tolerance=1e-5):\n",
    "    print(f\"Comparing outputs for {function_name}:\")\n",
    "    \n",
    "    if isinstance(torch_output, tuple) and isinstance(numpy_output, tuple):\n",
    "        for i, (torch_item, numpy_item) in enumerate(zip(torch_output, numpy_output)):\n",
    "            compare_single_output(torch_item, numpy_item, f\"{function_name}[{i}]\", tolerance)\n",
    "    else:\n",
    "        compare_single_output(torch_output, numpy_output, function_name, tolerance)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "def compare_single_output(torch_item, numpy_item, name, tolerance):\n",
    "    if isinstance(torch_item, torch.Tensor):\n",
    "        torch_item = torch_item.detach().cpu().numpy()\n",
    "    if isinstance(numpy_item, torch.Tensor):\n",
    "        numpy_item = numpy_item.detach().cpu().numpy()\n",
    "    \n",
    "    if not isinstance(torch_item, np.ndarray) or not isinstance(numpy_item, np.ndarray):\n",
    "        print(f\"  {name}: Cannot compare. Torch type: {type(torch_item)}, Numpy type: {type(numpy_item)}\")\n",
    "        return\n",
    "    \n",
    "    if torch_item.shape != numpy_item.shape:\n",
    "        print(f\"  {name}: Shape mismatch. Torch: {torch_item.shape}, Numpy: {numpy_item.shape}\")\n",
    "        return\n",
    "    \n",
    "    abs_diff = np.abs(torch_item - numpy_item)\n",
    "    max_diff = np.max(abs_diff)\n",
    "    mean_diff = np.mean(abs_diff)\n",
    "    \n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    Shape: {torch_item.shape}\")\n",
    "    print(f\"    Max absolute difference: {max_diff}\")\n",
    "    print(f\"    Mean absolute difference: {mean_diff}\")\n",
    "    \n",
    "    if max_diff > tolerance:\n",
    "        print(f\"    WARNING: Max difference exceeds tolerance of {tolerance}\")\n",
    "    else:\n",
    "        print(f\"    PASS: All differences within tolerance of {tolerance}\")\n",
    "\n",
    "# Usage in your code:\n",
    "model_torch = DeepConvNetTorch(input_dims=(3, 416, 416),\n",
    "                                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                                        max_pools=[0, 1, 2, 3, 4],\n",
    "                                        weight_scale='kaiming',\n",
    "                                        batchnorm=True,\n",
    "                                        dtype=torch.float32, device='cuda')\n",
    "model_numpy = DeepConvNetNumpy(input_dims=(3, 416, 416),\n",
    "                                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                                        max_pools=[0, 1, 2, 3, 4],\n",
    "                                        weight_scale='kaiming',\n",
    "                                        batchnorm=True,\n",
    "                                        dtype=torch.float32, device='cuda')\n",
    "\n",
    "checkpoint = torch.load('../../yolov2tiny_inference_numpy_version/weights_pytorch/yolov2_epoch_99.pth')\n",
    "pytorch_model = checkpoint['model']\n",
    "\n",
    "for param, val in model_torch.params.items():\n",
    "\tfor param1, val1 in pytorch_model.items():\n",
    "\t\tif (param == param1):\n",
    "\t\t\tmodel_torch.params[param] = val1.cuda()\n",
    "\n",
    "for param, val in model_numpy.params.items():\n",
    "\tfor param1, val1 in pytorch_model.items():\n",
    "\t\tif (param == param1):\n",
    "\t\t\tmodel_numpy.params[param] = val1.cuda()\n",
    "\n",
    "# Compare Forward\n",
    "X1 = im_data  # Your input data\n",
    "X2 = im_data2\n",
    "out_torch, cache_torch, _ = model_torch.Forward(X1)\n",
    "out_numpy, cache_numpy, _ = model_numpy.Forward(X2)\n",
    "compare_outputs((out_torch, cache_torch), (out_numpy, cache_numpy), \"Forward\")\n",
    "\n",
    "# Compare loss\n",
    "\n",
    "loss_torch, loss_grad_torch = model_torch.loss(out_torch, gt_boxes, gt_classes, num_obj)\n",
    "loss_numpy, loss_grad_numpy = model_numpy.loss(out_numpy, gt_boxes2, gt_classes2, num_obj2)\n",
    "# compare_outputs((loss_torch, loss_grad_torch), (torch.from_numpy(loss_numpy.data).float(), torch.from_numpy(loss_grad_numpy.data).float()), \"loss\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4136, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0129, device='cuda:0')\n",
      "\n",
      "Tensor(2.15729963) 1.0129129\n"
     ]
    }
   ],
   "source": [
    "print(loss_torch, loss_grad_torch.sum())\n",
    "print()\n",
    "print(loss_numpy, loss_grad_numpy.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1543, device='cuda:0', grad_fn=<AddBackward0>) Tensor(3.13565084)\n"
     ]
    }
   ],
   "source": [
    "print(loss_torch, loss_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m  \u001b[38;5;66;03m# Your upstream gradient\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m last_dout_torch, grads_torch \u001b[38;5;241m=\u001b[39m model_torch\u001b[38;5;241m.\u001b[39mbackward(dout, cache_torch)\n\u001b[1;32m      3\u001b[0m last_dout_numpy, grads_numpy \u001b[38;5;241m=\u001b[39m model_numpy\u001b[38;5;241m.\u001b[39mbackward(dout, cache_numpy)\n\u001b[1;32m      4\u001b[0m compare_outputs((last_dout_torch, grads_torch), (last_dout_numpy, grads_numpy), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/DOCKER_DIRS/wathna/2sep/yolov2tiny_inference/models_torch/torch_original.py:339\u001b[0m, in \u001b[0;36mDeepConvNetTorch.backward\u001b[0;34m(self, dout, cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dout, cache):\n\u001b[1;32m    338\u001b[0m     grads\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m--> 339\u001b[0m     dout \u001b[38;5;241m=\u001b[39m dout\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    340\u001b[0m     last_dout, dw, db  \u001b[38;5;241m=\u001b[39m Torch_FastConvWB\u001b[38;5;241m.\u001b[39mbackward(dout, cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    341\u001b[0m     grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW8\u001b[39m\u001b[38;5;124m'\u001b[39m], grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb8\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dw, db\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "dout = ...  # Your upstream gradient\n",
    "last_dout_torch, grads_torch = model_torch.backward(dout, cache_torch)\n",
    "last_dout_numpy, grads_numpy = model_numpy.backward(dout, cache_numpy)\n",
    "compare_outputs((last_dout_torch, grads_torch), (last_dout_numpy, grads_numpy), \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
